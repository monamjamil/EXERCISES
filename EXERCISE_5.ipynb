{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Introduction to Data Analytics - Exercise set 5 - data processing and management</b></h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all your exercises (Jupyter Notebooks or Python-files) in your course Git-project.\n",
    "Use either code comments or Jupyter Notebook markdown (text) to document which exercise you are doing and what a certain code section does! \n",
    "You can return all of these exercises in a single Jupyter Notebook, if you wish."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color: red;\"><b>NOTE: The JSON/XML –files in Moodle in these exercises have been randomly generated. In other words, the data doesn't make any sense!</b></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can import numpy and pandas here etc.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_read_xml as pdx\n",
    "import json\n",
    "from flatten_json import flatten\n",
    "import requests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>1. </b>Download <b>\"simple.json\"</b> in Moodle, and load it in pandas.</b> </h4>\n",
    "<p>\n",
    "The DataFrame should look like this:\n",
    "</p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex51.png\" width=\"1000\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>brand</th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "      <th>owned_by</th>\n",
       "      <th>acquired</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Chrysler</td>\n",
       "      <td>Voyager</td>\n",
       "      <td>2001</td>\n",
       "      <td>Wolff-Trantow</td>\n",
       "      <td>28/12/2016</td>\n",
       "      <td>11565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Jetta</td>\n",
       "      <td>1995</td>\n",
       "      <td>Schuppe, Pfeffer and Klein</td>\n",
       "      <td>20/4/2016</td>\n",
       "      <td>52431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Porsche</td>\n",
       "      <td>Cayenne</td>\n",
       "      <td>2005</td>\n",
       "      <td>Mante Group</td>\n",
       "      <td>11/6/2020</td>\n",
       "      <td>75552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Porsche</td>\n",
       "      <td>928</td>\n",
       "      <td>1994</td>\n",
       "      <td>Wisozk Group</td>\n",
       "      <td>17/6/2019</td>\n",
       "      <td>30331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>SL-Class</td>\n",
       "      <td>2007</td>\n",
       "      <td>Schiller-Littel</td>\n",
       "      <td>20/7/2018</td>\n",
       "      <td>62385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>Dodge</td>\n",
       "      <td>Ram 1500 Club</td>\n",
       "      <td>2000</td>\n",
       "      <td>Schneider-Donnelly</td>\n",
       "      <td>28/9/2016</td>\n",
       "      <td>56256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>GMC</td>\n",
       "      <td>Yukon XL 2500</td>\n",
       "      <td>2001</td>\n",
       "      <td>Powlowski, Lemke and Wiza</td>\n",
       "      <td>19/4/2016</td>\n",
       "      <td>50163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Sportvan G20</td>\n",
       "      <td>1992</td>\n",
       "      <td>O'Keefe, Rogahn and Gleichner</td>\n",
       "      <td>1/6/2019</td>\n",
       "      <td>8577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>Mitsubishi</td>\n",
       "      <td>3000GT</td>\n",
       "      <td>1993</td>\n",
       "      <td>Hoppe-Kunde</td>\n",
       "      <td>29/12/2018</td>\n",
       "      <td>23180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>TrailBlazer</td>\n",
       "      <td>2002</td>\n",
       "      <td>Wunsch-Friesen</td>\n",
       "      <td>14/11/2018</td>\n",
       "      <td>76830</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id          brand          model  year                       owned_by  \\\n",
       "0     1       Chrysler        Voyager  2001                  Wolff-Trantow   \n",
       "1     2     Volkswagen          Jetta  1995     Schuppe, Pfeffer and Klein   \n",
       "2     3        Porsche        Cayenne  2005                    Mante Group   \n",
       "3     4        Porsche            928  1994                   Wisozk Group   \n",
       "4     5  Mercedes-Benz       SL-Class  2007                Schiller-Littel   \n",
       "..  ...            ...            ...   ...                            ...   \n",
       "95   96          Dodge  Ram 1500 Club  2000             Schneider-Donnelly   \n",
       "96   97            GMC  Yukon XL 2500  2001      Powlowski, Lemke and Wiza   \n",
       "97   98      Chevrolet   Sportvan G20  1992  O'Keefe, Rogahn and Gleichner   \n",
       "98   99     Mitsubishi         3000GT  1993                    Hoppe-Kunde   \n",
       "99  100      Chevrolet    TrailBlazer  2002                 Wunsch-Friesen   \n",
       "\n",
       "      acquired  price  \n",
       "0   28/12/2016  11565  \n",
       "1    20/4/2016  52431  \n",
       "2    11/6/2020  75552  \n",
       "3    17/6/2019  30331  \n",
       "4    20/7/2018  62385  \n",
       "..         ...    ...  \n",
       "95   28/9/2016  56256  \n",
       "96   19/4/2016  50163  \n",
       "97    1/6/2019   8577  \n",
       "98  29/12/2018  23180  \n",
       "99  14/11/2018  76830  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code here\n",
    "df = pd.read_json('SIMPLE.json')\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>2.</b> Download <b>\"simple.xml\"</b> in Moodle, and load it in pandas</h4>\n",
    "<p>\n",
    "<span style=\"color: red\"><b>(Note:</b> if using pandas.read_xml(), use also the xpath-parameter!)</span><br /><br >The Series should look something like this:\n",
    "</p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex52.png\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex52cars.jpg\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>car</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand</th>\n",
       "      <td>Oldsmobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>Aurora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>owned_by</th>\n",
       "      <td>Herzog, Rodriguez and Howe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acquired</th>\n",
       "      <td>21/10/2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>32571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 car\n",
       "id                                 1\n",
       "brand                     Oldsmobile\n",
       "model                         Aurora\n",
       "year                            2003\n",
       "owned_by  Herzog, Rodriguez and Howe\n",
       "acquired                  21/10/2016\n",
       "price                          32571"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code here\n",
    "df = pdx.read_xml('SIMPLE.xml', root_is_rows= False)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>3. Load this API-data into a pandas DataFrame:</b></h4>\n",
    "<p><a href=\"https://edu.frostbit.fi/api/events/en\">https://edu.frostbit.fi/api/events/en</a></p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Remember to use json_normalize to help you out with the categories and address information.<br /><b>Have address information in their own columns, and categories as separate rows.</b><br />The DataFrame should look something like this (note that the data changes daily, and exact values will vary):\n",
    "\n",
    "\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex53.png\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex53events.jpg\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>categories0</th>\n",
       "      <th>categories1</th>\n",
       "      <th>categories2</th>\n",
       "      <th>categories3</th>\n",
       "      <th>categories4</th>\n",
       "      <th>categories5</th>\n",
       "      <th>addressstreet_address</th>\n",
       "      <th>addresspostal_code</th>\n",
       "      <th>categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Evening storytime</td>\n",
       "      <td>27.11.2024</td>\n",
       "      <td>cultural events</td>\n",
       "      <td>kilo</td>\n",
       "      <td>leppävaara</td>\n",
       "      <td>libraries</td>\n",
       "      <td>lintuvaara</td>\n",
       "      <td>literature</td>\n",
       "      <td>Leppävaarankatu 9</td>\n",
       "      <td>02600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Evening storytime</td>\n",
       "      <td>18.9.2024</td>\n",
       "      <td>cultural events</td>\n",
       "      <td>kilo</td>\n",
       "      <td>leppävaara</td>\n",
       "      <td>libraries</td>\n",
       "      <td>lintuvaara</td>\n",
       "      <td>literature</td>\n",
       "      <td>Leppävaarankatu 9</td>\n",
       "      <td>02600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Evening storytime</td>\n",
       "      <td>16.10.2024</td>\n",
       "      <td>cultural events</td>\n",
       "      <td>kilo</td>\n",
       "      <td>leppävaara</td>\n",
       "      <td>libraries</td>\n",
       "      <td>lintuvaara</td>\n",
       "      <td>literature</td>\n",
       "      <td>Leppävaarankatu 9</td>\n",
       "      <td>02600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Evening storytime</td>\n",
       "      <td>2.10.2024</td>\n",
       "      <td>cultural events</td>\n",
       "      <td>kilo</td>\n",
       "      <td>leppävaara</td>\n",
       "      <td>libraries</td>\n",
       "      <td>lintuvaara</td>\n",
       "      <td>literature</td>\n",
       "      <td>Leppävaarankatu 9</td>\n",
       "      <td>02600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Evening storytime</td>\n",
       "      <td>11.12.2024</td>\n",
       "      <td>cultural events</td>\n",
       "      <td>kilo</td>\n",
       "      <td>leppävaara</td>\n",
       "      <td>libraries</td>\n",
       "      <td>lintuvaara</td>\n",
       "      <td>literature</td>\n",
       "      <td>Leppävaarankatu 9</td>\n",
       "      <td>02600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Playground Loru’s schedule  6.5.-10.5.2024</td>\n",
       "      <td>6.5.2024</td>\n",
       "      <td>fine arts</td>\n",
       "      <td>music</td>\n",
       "      <td>playing (children's games)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Töölönlahdenkatu 4</td>\n",
       "      <td>00100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Evening storytime</td>\n",
       "      <td>13.11.2024</td>\n",
       "      <td>cultural events</td>\n",
       "      <td>kilo</td>\n",
       "      <td>leppävaara</td>\n",
       "      <td>libraries</td>\n",
       "      <td>lintuvaara</td>\n",
       "      <td>literature</td>\n",
       "      <td>Leppävaarankatu 9</td>\n",
       "      <td>02600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Evening storytime</td>\n",
       "      <td>4.9.2024</td>\n",
       "      <td>cultural events</td>\n",
       "      <td>kilo</td>\n",
       "      <td>leppävaara</td>\n",
       "      <td>libraries</td>\n",
       "      <td>lintuvaara</td>\n",
       "      <td>literature</td>\n",
       "      <td>Leppävaarankatu 9</td>\n",
       "      <td>02600</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Evening storytime</td>\n",
       "      <td>4.9.2024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Leppävaarankatu 9</td>\n",
       "      <td>02600</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Places and Hoods – See Helsinki Anew</td>\n",
       "      <td>9.5.2024</td>\n",
       "      <td>cultural events</td>\n",
       "      <td>everyday</td>\n",
       "      <td>helsinki residents</td>\n",
       "      <td>museums</td>\n",
       "      <td>urban history</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aleksanterinkatu 16</td>\n",
       "      <td>00170</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         name        date      categories0  \\\n",
       "0                           Evening storytime  27.11.2024  cultural events   \n",
       "1                           Evening storytime   18.9.2024  cultural events   \n",
       "2                           Evening storytime  16.10.2024  cultural events   \n",
       "3                           Evening storytime   2.10.2024  cultural events   \n",
       "4                           Evening storytime  11.12.2024  cultural events   \n",
       "5  Playground Loru’s schedule  6.5.-10.5.2024    6.5.2024        fine arts   \n",
       "6                           Evening storytime  13.11.2024  cultural events   \n",
       "7                           Evening storytime    4.9.2024  cultural events   \n",
       "8                           Evening storytime    4.9.2024              NaN   \n",
       "9        Places and Hoods – See Helsinki Anew    9.5.2024  cultural events   \n",
       "\n",
       "  categories1                 categories2 categories3    categories4  \\\n",
       "0        kilo                  leppävaara   libraries     lintuvaara   \n",
       "1        kilo                  leppävaara   libraries     lintuvaara   \n",
       "2        kilo                  leppävaara   libraries     lintuvaara   \n",
       "3        kilo                  leppävaara   libraries     lintuvaara   \n",
       "4        kilo                  leppävaara   libraries     lintuvaara   \n",
       "5       music  playing (children's games)         NaN            NaN   \n",
       "6        kilo                  leppävaara   libraries     lintuvaara   \n",
       "7        kilo                  leppävaara   libraries     lintuvaara   \n",
       "8         NaN                         NaN         NaN            NaN   \n",
       "9    everyday          helsinki residents     museums  urban history   \n",
       "\n",
       "  categories5 addressstreet_address addresspostal_code categories  \n",
       "0  literature     Leppävaarankatu 9              02600        NaN  \n",
       "1  literature     Leppävaarankatu 9              02600        NaN  \n",
       "2  literature     Leppävaarankatu 9              02600        NaN  \n",
       "3  literature     Leppävaarankatu 9              02600        NaN  \n",
       "4  literature     Leppävaarankatu 9              02600        NaN  \n",
       "5         NaN    Töölönlahdenkatu 4              00100        NaN  \n",
       "6  literature     Leppävaarankatu 9              02600        NaN  \n",
       "7  literature     Leppävaarankatu 9              02600        NaN  \n",
       "8         NaN     Leppävaarankatu 9              02600         []  \n",
       "9         NaN   Aleksanterinkatu 16              00170        NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code here\n",
    "url = \"https://edu.frostbit.fi/api/events/en\"\n",
    "response = json.loads(requests.get(url).text)\n",
    "\n",
    "flattened = (flatten(record, '') for record in response)\n",
    "df = pd.DataFrame(flattened)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>4. Use web scraping (e.g. BeautifulSoup), and use it to get the following info from the Rovaniemi Wikipedia –page</b></h4>\n",
    "<p><b>Wiki-page:</b> <a href=\"https://en.wikipedia.org/wiki/Rovaniemi\">https://en.wikipedia.org/wiki/Rovaniemi</a></p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Tasks:</b>\n",
    "<ul>\n",
    "    <li>Get the coordinates of Rovaniemi (upper right corner)</li>\n",
    "    <li>Get the nickname of Rovaniemi (under coat of arms)</li>\n",
    "</ul>\n",
    "\n",
    "<b>Advanced extra tasks:</b>\n",
    "<ul>\n",
    "    <li><b>Get the total population</b></li>\n",
    "    <ul>\n",
    "        <li><b>Note:</b> this is a good example why webscraping can be tedious, since you'll have to traverse the HTML-tree to get what you want. This might be helpful:<br />\n",
    "<a href=\"https://realpython.com/beautiful-soup-web-scraper-python/\">https://realpython.com/beautiful-soup-web-scraper-python/</a></li>\n",
    "    </ul>\n",
    "    \n",
    "</ul>\n",
    "\n",
    "<ul>\n",
    "    <li><b>Get the total area</b></li>\n",
    "    <ul>\n",
    "        <li>Convert this number into a float decimal (i.e. remove commas and the unit and call float() –in Python!)</li>\n",
    "    </ul>\n",
    "    \n",
    "</ul>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex54rovaniemi.jpg\" width=\"600\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66°30′N 025°44′E\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the Wikipedia page\n",
    "url = 'https://en.wikipedia.org/wiki/Rovaniemi'\n",
    "\n",
    "# Fetch the HTML content of the page\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "\n",
    "latitude = soup.find(class_='latitude')\n",
    "longitude = soup.find(class_='longitude')\n",
    "\n",
    "# Extract text content from the latitude and longitude elements\n",
    "latitude = latitude.text if latitude else None\n",
    "longitude = longitude.text if longitude else None\n",
    "\n",
    "# Print latitude and longitude\n",
    "print(latitude, longitude)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arctic Capital; Hometown of Santa Claus\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# URL of the Wikipedia page\n",
    "url = 'https://en.wikipedia.org/wiki/Rovaniemi'\n",
    "\n",
    "# Fetch the HTML content of the page\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find nickname by respective class name\n",
    "nickname = soup.find(class_='ib-settlement-nickname nickname')\n",
    "\n",
    "nickname = nickname.text.strip() if nickname else None\n",
    "\n",
    "# Print nickname\n",
    "print(nickname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<td class=\"infobox-data\">65,286</td>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# URL of the Wikipedia page\n",
    "url = 'https://en.wikipedia.org/wiki/Rovaniemi'\n",
    "\n",
    "# Fetch the HTML content of the page\n",
    "response = requests.get(url)  \n",
    "html_content = response.text\n",
    "\n",
    "# Parse the HTML content using BeautifulSoup\n",
    "soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "# Find the exact line by respective class name\n",
    "line = soup.find_all(class_='infobox-data')[9]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>5. Use web scraping, and create a DataFrame of this table: </b></h4>\n",
    "<p> <a href=\"https://en.wikipedia.org/wiki/List_of_countries_by_average_yearly_temperature\">https://en.wikipedia.org/wiki/List_of_countries_by_average_yearly_temperature</a></p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Change the name of the value column to \"avg_temp\" as well (pandas column rename)</li>\n",
    "</ul>\n",
    "\n",
    "<b>Advanced extra task:</b>\n",
    "<ul>\n",
    "    <li><b>Scrape these two tables as well</b></li>\n",
    "    <ul>\n",
    "        <li><a href=\"https://en.wikipedia.org/wiki/List_of_countries_by_employment_rate\">https://en.wikipedia.org/wiki/List_of_countries_by_employment_rate</a></li>\n",
    "        <li><a href=\"https://en.wikipedia.org/wiki/List_of_countries_by_unemployment_rate\">https://en.wikipedia.org/wiki/List_of_countries_by_unemployment_rate</a></li>\n",
    "    </ul>\n",
    "    <br />\n",
    "    <ul>\n",
    "        <li><b>Combine the tables into a single DataFrame so that you get only the data of year 2020 or newer, and have the columns <span style=\"color: darkorange\">\"Country\", \"EmploymentRate\"</span> and <span style=\"color: darkorange\">\"UnemploymentRate\"</span>. You can also create additional columns <span style=\"color: red\">\"EmploymentRate15_24\"</span>and <span style=\"color: red\">\" EmploymentRate25_70\"</span> if you scrape the OECD-table as well! </b>\n",
    "\n",
    "</li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex55stocks.jpg\" width=\"450\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>6. Simple merging:</b> Download <u><b>coffee_sales.csv</b></u> and <b><u>temperatures_fixed.csv</u></b> from Moodle.<b></h4>\n",
    "<p>Use merging to combine these files into one DataFrame, containing the coffee sales data and the corresponding temperature –data. (merge(), see materials for examples)</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red;\"><b>Use left join, and coffee sales as the first DataFrame!</b></span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_countries_by_average_yearly_temperature'\n",
    "page = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Extra task: </b> Do the same but with <b>temperatures_unfixed.csv</b> instead. Remember <b>groupby()</b> before attempting merging! \n",
    "\n",
    "<b>Also, you might want to remove some of the columns before grouping data => <span style=\"color: red;\">Summary + Hour</span>. </b>\n",
    "\n",
    "<span><i>You can also try to merge the DataFrames so that the Summary –of the weather is also added. For this, you probably need to figure out first how to determine the \"average\" Summary for each day (extra challenge!).</i></span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra task code here, if done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex56coffee.jpg\" width=\"450\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2><b>Advanced extra tasks for extra points (varying challenges, some require Googling):</b></h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>1. Download the \"complex.json\" –file from Moodle.</b> Note that this data is fairly complex (i.e. heavily nested). Use json_normalize and other needed methods to convert this data into a workable DataFrame.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for the advanced extra task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>2. Load the \"simple.json\" –file without pandas, and try to get the average price with plain Python. </li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for the advanced extra task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>3. Download the \"complex.xml\" file from Moodle, and create a DataFrame out of it.</b></li>\n",
    "<ul>\n",
    "    <li><b>Note:</b> using pandas.read_xml() would otherwise work, but it ignores the \"ownership\" –field. You'll have to find another way to get this data into your DataFrame as well!</li>\n",
    "</ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for the advanced extra task, you can also create a separate notebook for this \n",
    "# (might be a better idea, since a new dataset always adds quite much new code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><b>4. Try out Selenium on a site that cannot be scraped with traditional methods. You can use this tutorial as the starting point:</b></li>\n",
    "    <ul>\n",
    "        <li><a href=\"https://www.toptal.com/python/web-scraping-with-python\">https://www.toptal.com/python/web-scraping-with-python</a></li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for the advanced extra task, you can also create a separate notebook for this \n",
    "# (might be a better idea, since a new dataset always adds quite much new code)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_5/ex5charts.jpg\" width=\"600\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>5. Extra challenging advanced task: <span style=\"color: red;\">integrating data sources</span></b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>Integrate two or more datasets into one matching dataset  (pandas DataFrame), but use any datasets you can find in Kaggle instead of the previous coffee sales + temperature -datasets</b></li>\n",
    "<br />\n",
    "<ul>\n",
    "<li>Find two or more datasets (Kaggle etc.) that have something in common and can be used for merging. </li>\n",
    "</ul>\n",
    "\n",
    "<br />\n",
    "<ul>\n",
    "<li><b>Typical common columns:</b></li>\n",
    "<ul>\n",
    "<li>Coordinates (lat/lng etc.)</li>\n",
    "<li>Years, months</li>\n",
    "<li>reference ids (e.g. product id -> product data)</li>\n",
    "</ul>\n",
    "</ul>\n",
    "\n",
    "<br />\n",
    "<ul>\n",
    "<li><b>You can use pandas.merge() in order to combine DataFrames</b></li>\n",
    "<ul>\n",
    "<li>When combining DataFrames, make sure that the merge doesn’t mess up your data</li>\n",
    "<li><b>Note:</b> merge can often create way too many extra rows depending on the merging parameters</li>\n",
    "\n",
    "</ul>\n",
    "</ul>\n",
    "\n",
    "<br />\n",
    "<ul>\n",
    "<li><b>This exercise can provide even large amounts of points, depending on difficulty. Aspects that affect grading:</b></li>\n",
    "<ul>\n",
    "<li>Amount of datasets</li>\n",
    "<li>Difficulty of the datasets</li>\n",
    "<li>Using different data formats all at once (XML, JSON, CSV etc.)</li>\n",
    "<li>Other techniques used to add data: web scraping, data APIs etc.</li>\n",
    "</ul>\n",
    "</ul>\n",
    "\n",
    "\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this exercise is probably better to do in a separate Jupyter notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b393597a1a01400f99fd0b0bd7e53e32f7c09a6c4e3f1d7dcfe73f5e3a50c61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
