{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><b>Introduction to Data Analytics - Exercise set 2 - pandas-module</b></h3>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all your exercises (Jupyter Notebooks or Python-files) in your course Git-project.\n",
    "Use either code comments or Jupyter Notebook markdown (text) to document which exercise you are doing and what a certain code section does! \n",
    "You can return all of these exercises in a single Jupyter Notebook, if you wish."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>The datasets for these exercises have been collected from kaggle.com<br />\n",
    "(a service providing different datasets for practice)</b>\n",
    "\n",
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_2/es2_1.png\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>1. import pandas and read the csv-file found in Moodle (loans.csv). Use Python coding with pandas to answer the questions.</b></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'LOANS.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# and also load the needed csv-file\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLOANS.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m df\n",
      "File \u001b[1;32mc:\\Users\\PMLS\\Desktop\\ASSIGNMENTS\\VSC\\GITHUB\\EXERCISES\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PMLS\\Desktop\\ASSIGNMENTS\\VSC\\GITHUB\\EXERCISES\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\PMLS\\Desktop\\ASSIGNMENTS\\VSC\\GITHUB\\EXERCISES\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\PMLS\\Desktop\\ASSIGNMENTS\\VSC\\GITHUB\\EXERCISES\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\PMLS\\Desktop\\ASSIGNMENTS\\VSC\\GITHUB\\EXERCISES\\.venv\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'LOANS.csv'"
     ]
    }
   ],
   "source": [
    "# you can import numpy and pandas here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# and also load the needed csv-file\n",
    "df = pd.read_csv(\"LOANS.csv\")\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Remove the Customer ID –column from data</li>\n",
    "<li>Print the head of the data</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the column and print out the head of the DataFrame\n",
    "df.drop('Customer ID', axis = 1, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Remove rows from the data that have <b style=\"color: red;\">a too large of a loan</b> (Current Loan Amount should be less than 99999999)</li>\n",
    "    <ul>\n",
    "        <li><b>Tip:</b> use filtering!</li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove loans that are too large\n",
    "df = df[df['Current Loan Amount'] < 99999999]\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li>Remove rows that have the annual income as NaN (not a number)</li>\n",
    "    <ul>\n",
    "        <li><b>Extra task:</b> use imputation to use average income as the value instead of NaN</li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows if annual income is NaN\n",
    "df = df[df['Annual Income'].notnull()]\n",
    "\n",
    "# replacing NaN values with average value\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Get the average Current Loan Amount</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average current loan\n",
    "df['Current Loan Amount'].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Get the highest and lowest Annual Income in the dataset</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get highest and lowest annual income in dataset\n",
    "\n",
    "# highest\n",
    "highest = df['Annual Income'].max()\n",
    "highest\n",
    "\n",
    "# lowest\n",
    "lowest = df['Annual Income'].min()\n",
    "lowest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Get the Home Ownership value of the <b>Loan ID = bbf87a87-22cd-4d10-bd9b-7a9cc1b6e59d</b></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# get the needed value with the Loan ID\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mloc[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoan ID\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbbf87a87-22cd-4d10-bd9b-7a9cc1b6e59d\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      4\u001b[0m row_number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m491\u001b[39m\n\u001b[0;32m      5\u001b[0m column_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHome Ownership\u001b[39m\u001b[38;5;124m'\u001b[39m \n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# get the needed value with the Loan ID\n",
    "df.loc[df['Loan ID'] == 'bbf87a87-22cd-4d10-bd9b-7a9cc1b6e59d']\n",
    "\n",
    "row_number = 491\n",
    "column_name = 'Home Ownership' \n",
    "\n",
    "desired_value = df.loc[row_number , column_name]\n",
    "desired_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Create a new field into your dataset called <b>Actual Annual Income</b>.</li>\n",
    "<br><b>Note:</b> The Actual Annual Income follow this formula:<br>\n",
    "<b style=\"color: green\">Annual Income – 12 * Monthly Debt</b><br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new field for Actual Annual income (annual income - 12 * monthly debt)\n",
    "df['Actual Annual Income'] = df['Annual Income'] - 12 * df['Monthly Debt']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Get the Actual Annual Income of the loan with the <b>ID = 76fa89b9-e6a8-49af-afa1-8151315aba8e</b></li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the Actual Annual income for the needed ID\n",
    "df.loc[df['Loan ID'] == '76fa89b9-e6a8-49af-afa1-8151315aba8e']\n",
    "\n",
    "row_number = 109\n",
    "column_name = 'Actual Annual Income' \n",
    "\n",
    "desired_value = df.loc[row_number , column_name]\n",
    "desired_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Get the Loan ID of the loan with the smallest Actual Annual Income </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get loan ID of lowest actual annual income\n",
    "# find the lowest value\n",
    "lowest = df['Actual Annual Income'].min()\n",
    "lowest\n",
    "\n",
    "\n",
    "# locate the row with the lowest value\n",
    "df.loc[df['Actual Annual Income'] == 66481.0]\n",
    "\n",
    "# make the fucntion to find the desired value\n",
    "row_number = 66089\n",
    "column_name = 'Loan ID'\n",
    "\n",
    "desired_value = df.loc[row_number , column_name]\n",
    "desired_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>How many loans are \"Long term\"?</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce code that shows many loans are long term\n",
    "df['Term'].value_counts()['Long Term']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>How many loaners have more than 1 bankruptcy?</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce code that shows how many loaners have more than 1 bankruptcy\n",
    "df[df['Bankruptcies'] > 1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>How many Short Term loans are for Home Improvements?</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce code that shows how many of the Short Term loans are for Home Improvements\n",
    "df[(df['Term'] == 'Short Term') \n",
    "   &\n",
    "   (df['Purpose'] == 'Home Improvements')\n",
    "   ].count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>How many unique loan purposes are there?</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce code that shows how many unique loan purposes there are\n",
    "unique_values = df['Purpose'].nunique()\n",
    "unique_values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>What are the 3 most common loan purposes?</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce code that shows the 3 most common loan purposes\n",
    "df['Purpose'].value_counts().head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Is there a correlation between <b>Annual Income</b> and <b>Number of Open Accounts</b> or is there a correlation between <b>Number of Credit Problems</b> and <b>Bankruptcies</b>?</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce code that shows which correlation statement is true\n",
    "\n",
    "# first correlation = False\n",
    "correlation = df['Annual Income'].corr(df['Number of Open Accounts'])\n",
    "correlation\n",
    "\n",
    "# second correlation = True as it has a higher percentage\n",
    "correlation = df['Number of Credit Problems'].corr(df['Bankruptcies'])\n",
    "correlation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>2. Download the purchases.csv from Moodle, and do the following observations:</b></h4>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>What was the total price sum of the Purchase Order Number 018H2015? (14 rows in total)</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce the code that gets the needed total price sum\n",
    "filtered_df = df[df['Purchase Order Number'] == '018H2015']\n",
    "\n",
    "sum = filtered_df['Total Price'].sum()\n",
    "sum"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>What is the name and description of the purchased item with the Purchase Order Number 3176273?</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce the code that gets the needed name and description\n",
    "df.loc[df['Purchase Order Number'] == '3176273']\n",
    "\n",
    "desired_value = df.iloc[103, [14, 15]]\n",
    "desired_value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>How many occasions (rows) of purchase data happened during the year 2013?</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# produce the code that filters the needed data for year 2013\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPurchase Date\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPurchase Date\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m years \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPurchase Date\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2013\u001b[39m]\n\u001b[0;32m      4\u001b[0m years[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPurchase Date\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcount()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# produce the code that filters the needed data for year 2013\n",
    "df['Purchase Date'] = pd.to_datetime(df['Purchase Date'], format='%m/%d/%Y', errors='coerce')\n",
    "years = df[df['Purchase Date'].dt.year == 2013]\n",
    "years['Purchase Date'].count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul><li>What are the 5 most common Departments in the data?</li>\n",
    "<ul><li><b>Extra task: </b>What are 3 Departments using most money in the data?</li></ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce the code that gtest the needed most common departments\n",
    "top_values = df['Department Name'].value_counts().head(5)\n",
    "top_values\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Sort the data by Department Name</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the data by department name\n",
    "sorted = df.sort_values(by=['Department Name'])\n",
    "sorted"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>Small extra tasks for extra points</b></li>\n",
    "<ul>\n",
    "<li>How many purchases in the data were IT Goods and had the total price more than 50000 dollars?</li>\n",
    "<li>How many of the purchases have anything to do with IT? (IT Goods, IT Services, IT Telecommunications)</li>\n",
    "\n",
    "</ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce the code for the extra tasks if you wish complete them\n",
    "it_goods = df[df['Acquisition Type'] == 'IT Goods']\n",
    "it_goods\n",
    "\n",
    "greater = it_goods[it_goods['Total Price'] > 50000]\n",
    "greater['Total Price'].count()\n",
    "\n",
    "# anything to do with It\n",
    "It = df[(df['Acquisition Type'] == 'It goods') | (df['Acquisition Type'] =='IT Services') | (df['Acquisition Type'] =='IT Telecommunications')]\n",
    "It['Acquisition Type'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>Other extra tasks for extra points</b></li>\n",
    "<ul>\n",
    "<li>Create a new DataFrame, where you have filtered out purchases that have a Total Price of 0 or less</li>\n",
    "<li>For this DataFrame, use groupby() –function twice to group the purchases data by Acquisition Type, and then calculating the result first by sum() and then by mean()</li>\n",
    "<li>Which two acquisition types have the largest sums and means after grouping the data?</li>\n",
    "</ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce the code for the extra tasks if you wish complete them\n",
    "new = df.copy()\n",
    "new[new['Total Price'] <= 0]\n",
    "new\n",
    "\n",
    "# groupby\n",
    "mean_group = new.drop(columns=['Purchase Date']).groupby('Acquisition Type').mean()\n",
    "mean_group"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_2/es2_2.png\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><b>3. Download the data_salaries_india.csv from Moodle, and consider the following questions of the data. Use any means in pandas (or even NumPy) you wish to explain your answers.</b></h4>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Before we can do anything with the salaries, we have to convert them into something more usable</li>\n",
    "<ul>\n",
    "<li>Note: the salaries can be yearly, monthly or hourly salaries</li>\n",
    "<ul>\n",
    "<li>We don't also need the Indian rupee –sign (₹)</li>\n",
    "</ul>\n",
    "<li>You can use the template in Moodle to help you out with this (Salary filtering, pandas exercise 3)</li>\n",
    "</ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the salaries as needed\n",
    "df = pd.read_csv(\"SALARIES.csv\")\n",
    "\n",
    "df['Salary'] = df['Salary'].str.replace('₹', '')\n",
    "df\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>What are the most common values in different fields (Job Titles, Companies, Location)? <b>Based on the distribution, is the data balanced or not?</b></li>\n",
    "<ul>\n",
    "<li><b>Extra task:</b> there seem to be some Job Titles that are almost the same, like \"Machine Learning Data Associate\" and \"Machine Learning Associate\", combine these into something common</li>\n",
    "</ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce the code that shows the most common values in different fields\n",
    "columns = ['Company Name' , 'Job Title' , 'Location']\n",
    "common = df[columns].mode()\n",
    "common\n",
    "\n",
    "# and answer the question about the distribution\n",
    "\n",
    "\n",
    "# similar names\n",
    "replace = {'Machine Learning Data Associate' : 'Machine Learning Associate' , 'Machine Learning Associate' : 'Machine Learning Associate'}\n",
    "df['Job Title'] = df['Job Title'].replace(replace)\n",
    "df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>Are there any outliers in the data that might affect the averages negatively (certain salaries)? Manage the outliers as you best see fit (either remove them or leave them, based on your analysis) </li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce the code that shows the potential outliers and take care of them as you see fit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>If we want to correlate upon categories (ordinal or binary), we need to use factorize(). <b>Factorize the Role-column, and add the new column to the DataFrame.</b></li>\n",
    "<ul>\n",
    "<li><b>Note:</b> using <b>factorize()</b> for nominal categories (Job Title, Location, Company Name) doesn't work well, because the numbers do not have any numeric magnitude. In other words, these categories don't measure anything, they just group data, so numerical comparison / correlation doesn't mean anything statistically.</li>\n",
    "</ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example:\n",
    "# factorize Role level into numbers\n",
    "# label1, unique1 = pd.factorize(df['Role'], sort=False)\n",
    "# df['ManagerRole'] = label1\n",
    "\n",
    "# produce the needed factorization for Role-column"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>Finally, check out the correlations. Does anything correlate with anything? Can we make any assumptions?</b></li>\n",
    "<ul>\n",
    "<li>Tip: When correlating against binary variables, sometimes the Spearman correlation might be more sensitive, in pandas:</li>\n",
    "</ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember: df.corr(method=\"spearman\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Extra tasks for this dataset</b><br><br>\n",
    "\n",
    "<ul>\n",
    "<li>After all salaries have been converted to correct format by using the helper function (check Moodle), use quantiles and split the data into four different parts:</li>\n",
    "<ul>\n",
    "<li><span style=\"color: red;\">Top 25%</span><br>=> quantile(0.75)</li>\n",
    "<li><span style=\"color: red;\">Above average, values between top 25-50%</span><br>\n",
    "=> quantile(0.5)  - quantile(0.75)</li>\n",
    "<li><span style=\"color: red;\">Below average, values between top 50-75% </span><br>\n",
    "=> quantile(0.25) – quantile(0.5)\n",
    "</li>\n",
    "<li><span style=\"color: red;\">Bottom 25%</span><br>=> quantile(0.25)</li>\n",
    "<br>\n",
    "<li>What are the salary ranges for each quantile?</li><li>\n",
    "See examples in pandas-materials on how to use quantiles\n",
    "</li>\n",
    "</ul>\n",
    "</ul>\n",
    "<hr>\n",
    "\n",
    "<ul>\n",
    "<li>Did you get any ideas how this data could be improved? Do we need some particular new data or some other operations on the data? Should we filter something out based on some other column?<br><br><b>Provide arguments for your answers in code comments.</b><br><br> </li>\n",
    "<ul>\n",
    "<li>Note: There are many good possible answers here!</li>\n",
    "<li>Tip: How about replacing the \"Salaries Reported\" column with actual rows based on that number? Try doing this with the data!</li>\n",
    "<li>Remember: This data only represents data engineering salaries based on selected Indian cities.\n",
    "The world is a vast place :)\n",
    "</li>\n",
    "</ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for the extra tasks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<h2><b>Advanced extra tasks for extra points (varying challenges, some require Googling):</b></h2>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>1. Data merge is a useful tool when you have multiple files of data that have the exact same structure.</b><br><br>Download the two csv-files from Moodle (videogames1.csv, videogames2.csv), and combine them into one Data Frame. Lastly, save the Data Frame into a new csv-file => combined.csv.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for the advanced extra task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>2. Functions and lambdas allow us to extend the operations we wish to do to columns and rows in pandas. </b><br><br>For example, the built-in functions may not be enough in all cases. Use the data of exercise 1 (loans.csv), and create a new column called \"Income Group\" that holds a text value. <br><br>Create either a function or a lambda, that determines the True or False –value based on the Annual Income –column. Use the following table to create the values:</li>\n",
    "</ul>\n",
    "\n",
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_2/es2_3.png\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<li>After creating the function/lambda, you can use it by using pandas' .apply() –function.<br><br></li>\n",
    "\n",
    "<li>Finally, get the amount of rows grouped by each of the new Income Group –field values and print them out.</li> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for the advanced extra task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>3.\tNormalization allows us to convert the values of numeric columns to be between 0 and 1.</b> This is helpful when two different numbers seem to follow the same trend, but have completely different value ranges. For example, gold and silver prices tend to follow similar patterns, but their market worth is quite different. By using normalization, we can compare these trends more easily. <br>\n",
    "\n",
    "Get historical prices of both gold and silver, and compare them without and with normalization. You can plot the prices by using df.plot() –function. Check the dataset in list in Moodle for some alternatives for gold and silver prices.\n",
    "</li>\n",
    "</ul>\n",
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_2/es2_4.png\" />"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><b>4.\tCreate an account to kaggle.com, and find any dataset that interests you. </b><br>\n",
    "\n",
    "There's a list of possibly interesting datasets listed in Moodle as well.\n",
    "<br><br>\n",
    "<b>Try to find interesting features in data, in particular:</b>\n",
    "</li>\n",
    "<ul>\n",
    "<li>Clean up data first (rows with too many NaN –values), values that are way too big or small, insignificant columns etc.)</li>\n",
    "<li>You can create new columns as well if it seems suitable! (either by using functions or other means)</li>\n",
    "<li>Interesting correlations (.corr() –function) and other interesting features in the data. Is something surprising in the data?</li>\n",
    "<li><b>Note: </b>There are many ways on how to approach this exercise.</li>\n",
    "</ul>\n",
    "</ul>\n",
    "\n",
    "<img src=\"http://srv.plab.fi/~tuomasv/data_analytics_2023_images/exercise_set_2/es2_5.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do any Kaggle.com -related extra tasks in their own Jupyter notebooks for easier coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b393597a1a01400f99fd0b0bd7e53e32f7c09a6c4e3f1d7dcfe73f5e3a50c61"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
